{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956eb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89f2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citation_graph(file_path):\n",
    "    adjacency_list = {}\n",
    "    node_list = set()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line into source and target vertices\n",
    "            target, source = map(int, line.strip().split())\n",
    "            node_list.add(source)\n",
    "            node_list.add(target)\n",
    "\n",
    "            # Add the edge to the adjacency list\n",
    "            if source in adjacency_list:\n",
    "                adjacency_list[source].append(target)\n",
    "            else:\n",
    "                adjacency_list[source] = [target]\n",
    "\n",
    "    return adjacency_list, node_list\n",
    "\n",
    "def add_sink_nodes(graph, node_list):\n",
    "    graph_nodes = list(graph.keys())\n",
    "    sink_nodes = []\n",
    "    for node in node_list:\n",
    "        if node not in graph_nodes:\n",
    "            # graph[node] = []\n",
    "            sink_nodes.append(node)\n",
    "\n",
    "    for node in sink_nodes:\n",
    "        add_nodes = []\n",
    "        for key, values in graph.items():\n",
    "            if node in values:\n",
    "                add_nodes.append(key)\n",
    "        graph[node] = add_nodes\n",
    "\n",
    "    return graph\n",
    "\n",
    "def find_shortest_paths(start, end, graph, dist):\n",
    "    if start == end:\n",
    "        return [[start]]\n",
    "    \n",
    "    paths = []\n",
    "    for neighbor in graph[start]:\n",
    "        if dist[start][end] == dist[neighbor][end] + 1:\n",
    "            for path in find_shortest_paths(neighbor, end, graph, dist):\n",
    "                paths.append([start] + path)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# def all_shortest_paths(graph):\n",
    "#     INF = float('inf')\n",
    "#     n = len(graph)\n",
    "#     nodeList = list(graph.keys())\n",
    "    \n",
    "#     # Initialize the distance matrix\n",
    "#     # dist = [[INF] * n for _ in range(n)]\n",
    "#     dist = {}\n",
    "\n",
    "#     for node in nodeList:\n",
    "#         temp = {}\n",
    "#         for adj in nodeList:\n",
    "#             temp[adj] = INF\n",
    "#         dist[node] = temp\n",
    "\n",
    "#     for i in nodeList:\n",
    "#         dist[i][i] = 0\n",
    "#         for neighbor in graph[i]:\n",
    "#             dist[i][neighbor] = 1  # Assuming every edge cost is 1\n",
    "    \n",
    "#     print('Running Floyd-Warshall ...\\n')\n",
    "#     # Floyd-Warshall algorithm\n",
    "#     for k in nodeList:\n",
    "#         for i in nodeList:\n",
    "#             for j in nodeList:\n",
    "#                 dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])\n",
    "    \n",
    "#     print('Extracting shortest paths ... \\n')\n",
    "#     # Extract all shortest paths\n",
    "#     #paths = [[[] for _ in nodeList] for _ in nodeList]\n",
    "#     paths = {}\n",
    "\n",
    "#     for node in nodeList:\n",
    "#         temp = {}\n",
    "#         for adj in nodeList:\n",
    "#             temp[adj] = []\n",
    "#         paths[node] = temp\n",
    "\n",
    "#     for i in nodeList:\n",
    "#         for j in nodeList:\n",
    "#             if dist[i][j] != INF:\n",
    "#                 paths[i][j] = find_shortest_paths(i, j, graph, dist)\n",
    "    \n",
    "#     return paths, dist\n",
    "\n",
    "def shortest_paths_bfs(graph, start):\n",
    "    # Initialize distances dictionary to store the shortest distances\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    \n",
    "    # Set the distance to the start node as 0\n",
    "    distances[start] = 0\n",
    "    \n",
    "    # Initialize a queue for BFS\n",
    "    queue = deque([start])\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.popleft()\n",
    "\n",
    "        for neighbor in graph[current_node]:\n",
    "            if distances[neighbor] == float('inf'):\n",
    "                # If the distance is infinite, update it and enqueue the neighbor\n",
    "                distances[neighbor] = distances[current_node] + 1\n",
    "                queue.append(neighbor)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def all_shortest_paths(graph):\n",
    "    INF = float('inf')\n",
    "    dist = {}\n",
    "    nodeList = list(graph.keys())\n",
    "    \n",
    "    # Iterate through all nodes and find shortest paths from each node\n",
    "    print('Retrieving shortest path distances ...\\n')\n",
    "    for node in graph:\n",
    "        dist[node] = shortest_paths_bfs(graph, node)\n",
    "\n",
    "    print('Extracting shortest paths ... \\n')\n",
    "    # Extract all shortest paths\n",
    "    #paths = [[[] for _ in nodeList] for _ in nodeList]\n",
    "    paths = {}\n",
    "\n",
    "    for node in nodeList:\n",
    "        temp = {}\n",
    "        for adj in nodeList:\n",
    "            temp[adj] = []\n",
    "        paths[node] = temp\n",
    "\n",
    "    for i in nodeList:\n",
    "        for j in nodeList:\n",
    "            if dist[i][j] != INF:\n",
    "                paths[i][j] = find_shortest_paths(i, j, graph, dist)\n",
    "    \n",
    "    return paths, dist\n",
    "\n",
    "def get_closeness_centrality(distance_dict):\n",
    "    n = len(distance_dict)\n",
    "    centrality_scores = {}\n",
    "\n",
    "    for node, distances in distance_dict.items():\n",
    "        for key, value in distances.items():\n",
    "            if value == float('inf'):\n",
    "                distance_dict[node][key] = 0\n",
    "                \n",
    "        total_distance = sum(list(distance_dict[node].values()))\n",
    "        closeness_centrality = (n - 1) / total_distance if total_distance != 0 else 0\n",
    "        centrality_scores[node] = closeness_centrality\n",
    "\n",
    "    centrality_scores = {k: v for k, v in sorted(centrality_scores.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "    return centrality_scores\n",
    "\n",
    "def get_betweenness_centrality(shortest_path_list):\n",
    "\n",
    "    nodeList = list(shortest_path_list.keys())\n",
    "    n = len(nodeList)\n",
    "    # print('Computing shortest paths between each pair of node ...\\n')\n",
    "    # shortest_path_list = all_shortest_paths(graph)\n",
    "    bet_centrality = {}\n",
    "\n",
    "    for node in nodeList:\n",
    "        # print(f'Computing betweenness centrality for node {node}\\n')\n",
    "        centrality = 0\n",
    "        for i, pathList in shortest_path_list.items(): # list of all shortest paths for each node i to all node j\n",
    "            for j, shortest_paths in pathList.items(): # list of all shortest paths from node i to node j\n",
    "                tot_path_i_j = len(shortest_paths)\n",
    "                i_node_j = 0 \n",
    "                for path in shortest_paths: # one of the shortest path from i to j\n",
    "                    path_len = len(path)\n",
    "                    if node in path and node != path[0] and node != path[path_len-1]:\n",
    "                        i_node_j += 1\n",
    "\n",
    "                centrality += i_node_j / tot_path_i_j if tot_path_i_j != 0 else 0\n",
    "\n",
    "        bet_centrality[node] = centrality / ((n-1) * (n-2))\n",
    "\n",
    "    bet_centrality = {k: v for k, v in sorted(bet_centrality.items(), key=lambda item: item[1], reverse = True)}\n",
    "    return bet_centrality\n",
    "\n",
    "def get_pagerank(graph, damping_factor=0.8, epsilon=1e-8, max_iterations=100):\n",
    "    nodeList = list(graph.keys())\n",
    "    num_nodes = len(nodeList)\n",
    "    node_dir = {}\n",
    "\n",
    "    i = 0\n",
    "    for node in nodeList:\n",
    "        node_dir[node] = i\n",
    "        i += 1\n",
    "\n",
    "    transition_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    for node, neighbors in graph.items():\n",
    "        if neighbors:\n",
    "            num_neighbors = len(neighbors)\n",
    "            for neighbor in neighbors:\n",
    "                x = node_dir[neighbor]\n",
    "                y = node_dir[node]\n",
    "                transition_matrix[x, y] = 1 / num_neighbors\n",
    "\n",
    "    # Damping factor\n",
    "    damping_matrix = (1 - damping_factor) / num_nodes * np.ones((num_nodes, num_nodes))\n",
    "    transition_matrix = damping_factor * transition_matrix + damping_matrix\n",
    "\n",
    "    # Initial PageRank values\n",
    "    page_rank_vector = np.ones(num_nodes) / num_nodes\n",
    "\n",
    "    # Power iteration method to calculate PageRank\n",
    "    for i in range(max_iterations):\n",
    "        # print('Iteration:', i)\n",
    "        new_page_rank = np.dot(transition_matrix, page_rank_vector)\n",
    "        if np.linalg.norm(new_page_rank - page_rank_vector, ord=1) < epsilon:\n",
    "            break\n",
    "        page_rank_vector = new_page_rank\n",
    "\n",
    "    page_rank_final = {}\n",
    "    for node in nodeList:\n",
    "        page_rank_final[node] = page_rank_vector[node_dir[node]]\n",
    "\n",
    "    page_rank_final = {k: v for k, v in sorted(page_rank_final.items(), key=lambda item: item[1], reverse = True)}\n",
    "    \n",
    "    return page_rank_final\n",
    "\n",
    "def write_file(file_name, data_dict):\n",
    "    file_path = './' + file_name\n",
    "    with open(file_path, 'w') as file:\n",
    "        for node, centrality in data_dict.items():\n",
    "            file.write('{} {:.6f}\\n'.format(node, centrality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed992da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching the graph ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = './demo.txt'\n",
    "# file_path = './cora/cora.cites'\n",
    "print('Fetching the graph ...\\n')\n",
    "citation_network, node_list = get_citation_graph(file_path)\n",
    "citation_network = add_sink_nodes(citation_network, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db26e7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving shortest path distances ...\n",
      "\n",
      "Extracting shortest paths ... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# shortest_paths, dist = all_shortest_paths(citation_network)\n",
    "shortest_paths, dist = all_shortest_paths(citation_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15494086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {1: [[1]], 2: [[1, 0, 2]], 3: [], 0: [[1, 0]]},\n",
       " 2: {1: [[2, 1]], 2: [[2]], 3: [], 0: [[2, 0]]},\n",
       " 3: {1: [[3, 1]], 2: [[3, 2]], 3: [[3]], 0: [[3, 2, 0], [3, 1, 0]]},\n",
       " 0: {1: [[0, 1]], 2: [[0, 2]], 3: [], 0: [[0]]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88be57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_centrality = get_closeness_centrality(dist)\n",
    "write_file('closeness.txt', closeness_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e0b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality = get_betweenness_centrality(shortest_paths)\n",
    "write_file('beetweenness.txt', betweenness_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd50014",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = get_pagerank(citation_network)\n",
    "write_file('pagerank.txt', pagerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ded257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('distance.pickle', 'wb') as handle:\n",
    "#     pickle.dump(dist, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('shortest_paths.pickle', 'wb') as handle:\n",
    "#     pickle.dump(shortest_paths, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "with open('distance.pickle', 'rb') as handle:\n",
    "    dist = pickle.load(handle)\n",
    "\n",
    "with open('shortest_paths.pickle', 'rb') as handle:\n",
    "    shortest_paths = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6457f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
